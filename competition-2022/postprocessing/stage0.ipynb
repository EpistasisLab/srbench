{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a677625",
   "metadata": {},
   "source": [
    "# Stage 0: Filtering\n",
    "\n",
    "In this stage, models must do better than linear regression in terms of average head-to-head rankings with linear regression,  \n",
    "based on `r2_score` on test sets in order to continue to stage 1 and 2. \n",
    "\n",
    "## Results\n",
    "Based on the results of this stage, 3 algorithms (HROCH, nsga2-dcgp, and TaylorGP) were eliminated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1e4ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f8b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdir = '../results_stage0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4778c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "i = 0\n",
    "for f in Path(rdir).rglob('*.json'):\n",
    "#     print(f)\n",
    "    with open(f, 'r') as of:\n",
    "        d = json.load(of)\n",
    "    frames.append(d)\n",
    "    i += 1\n",
    "    \n",
    "print('loaded',i,'results')\n",
    "df = pd.DataFrame.from_records(frames)\n",
    "\n",
    "########################################\n",
    "# get dataset sizes\n",
    "dataset_nsamples = {}\n",
    "dataset_nfeatures = {}\n",
    "    \n",
    "for d in df.dataset.unique():\n",
    "    tmp = pd.read_csv('../experiment/data/stage0/'+d+'.tsv.gz', sep='\\t')\n",
    "    dataset_nsamples[d] = len(tmp)\n",
    "    dataset_nfeatures[d] = tmp.shape[1]-1\n",
    "\n",
    "ns = pd.DataFrame({'dataset':dataset_nsamples.keys(),\n",
    "              'nsamples':dataset_nsamples.values(),\n",
    "             })\n",
    "nf = pd.DataFrame({'dataset':dataset_nfeatures.keys(),\n",
    "              'nfeatures':dataset_nfeatures.values(),\n",
    "             })\n",
    "data = pd.merge(ns,nf,on='dataset')\n",
    "df = df.merge(data,on='dataset')\n",
    "df['nsize'] = df['nsamples'].apply(lambda x: '>10,000' if x>10000 else '>1000' if x>1000 else '<=1000')\n",
    "df['fsize'] = df['nfeatures'].apply(lambda x: '>=1000' if x>=1000 else '>=100' if x>=100 else '<100')\n",
    "########################################\n",
    "# time transform\n",
    "df['time_hr'] = df['time_time']/3600\n",
    "df['time_mins'] = df['time_time']/60\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35200bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.algorithm.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1bb1ba",
   "metadata": {},
   "source": [
    "# check run completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e29af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['nsamples','nfeatures','dataset','algorithm'])['random_state'].count().unstack()-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc49be0c",
   "metadata": {},
   "source": [
    "# get rankings \n",
    "\n",
    "- if a result is missing, it is assigned worst rank. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e29939",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = df.random_state.unique()\n",
    "datasets= df.dataset.unique()\n",
    "algorithms= df.algorithm.unique()\n",
    "\n",
    "    \n",
    "metrics = [c for c in df.columns if c.endswith('test')]\n",
    "for col in metrics:\n",
    "    ascending = 'r2' not in col\n",
    "    df[col+'_rank_per_trial']=(df.groupby(['dataset','random_state'])\n",
    "                               [col].apply(lambda x:  round(x,3).rank( ascending=ascending))\n",
    "                              )\n",
    "rank_metrics = [c+'_rank_per_trial' for c in metrics]\n",
    "met_worst = {}\n",
    "for m in rank_metrics:\n",
    "    met_worst[m] = df[m].max() + 1\n",
    "    \n",
    "frames = [] \n",
    "for s in seeds:\n",
    "    for d in datasets:\n",
    "        for alg in algorithms:\n",
    "            dfsdalg = df.loc[(df.random_state==s) \n",
    "                             & (df.dataset==d)\n",
    "                             & (df.algorithm==alg)\n",
    "                            ]\n",
    "            if len(dfsdalg) == 0:\n",
    "                entry = {\n",
    "                    'dataset':d,\n",
    "                    'random_state':s,\n",
    "                    'algorithm':alg\n",
    "                } \n",
    "                for m in rank_metrics:\n",
    "                    entry[m] = met_worst[m]\n",
    "#                 print(f'missing {s},{d},{alg} filled with {entry}')\n",
    "                frames.append(entry) \n",
    "df_missing = pd.DataFrame.from_records(frames)\n",
    "df = df.append(df_missing).reset_index()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58146f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d952f01d",
   "metadata": {},
   "source": [
    "# get difference from linear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9476d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp = df.set_index(['random_state','dataset'])\n",
    "lr = tmp.loc[tmp.algorithm=='LinearRegression']\n",
    "lr\n",
    "frames = []\n",
    "for alg in tmp.algorithm.unique():\n",
    "    diff = (tmp.loc[tmp.algorithm==alg]['r2_test'] - lr['r2_test'])/np.abs(lr['r2_test'])*100\n",
    "    diff = pd.DataFrame(diff.rename('r2_test_diff'))\n",
    "    diff['r2_test_rank_diff'] = (tmp.loc[tmp.algorithm==alg]['r2_test_rank_per_trial'] \n",
    "                                 - lr['r2_test_rank_per_trial'])\n",
    "    diff['algorithm'] = alg\n",
    "    frames.append(diff)\n",
    "    \n",
    "df_diff = pd.concat(frames).reset_index()\n",
    "# r2_test_diff\n",
    "# frames\n",
    "df = pd.merge(df, df_diff, on = ['random_state','dataset','algorithm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41a8f21",
   "metadata": {},
   "source": [
    "# summarize trials by dataset\n",
    "- summarize metrics so that we're looking at aggregates of aggregate dataset performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b323fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum = df.groupby(['algorithm','dataset'],as_index=False).median()\n",
    "df_sum['rmse_test'] = df_sum['mse_test'].apply(np.sqrt)\n",
    "df_sum['log_mse_test'] = df_sum['mse_test'].apply(lambda x: np.log(1+x))\n",
    "\n",
    "# rankings and normalized scores per dataset\n",
    "for col in [c for c in df_sum.columns if 'test' in c or c.endswith('size')]:\n",
    "    ascending = 'r2' not in col or 'rank' in col\n",
    "    df_sum[col+'_rank']=df_sum.groupby(['dataset'])[col].apply(lambda x: \n",
    "                                                                        round(x,3).rank(ascending=ascending)\n",
    "                                                                  )\n",
    "    df_sum[col+'_norm'] = df_sum.groupby('dataset')[col].apply(lambda x: (x-x.min())/(x.max()-x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b3a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7345c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum.groupby(['dataset','algorithm'])['r2_test'].median().unstack().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26769d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum.groupby(['dataset','algorithm'])['r2_test_rank_per_trial_rank'].median().unstack().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea6da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum.groupby(['algorithm','dataset'])['r2_test_diff'].median().unstack().round().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6428ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum.groupby(['algorithm'])['r2_test_diff'].median().round().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadc8ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['algorithm','dataset'])['r2_test_rank_diff'].median().unstack().round().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4b100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipdb\n",
    "seeds = df.random_state.unique()\n",
    "print(seeds)\n",
    "datasets= df.dataset.unique()\n",
    "print(datasets)\n",
    "missing = pd.DataFrame()\n",
    "for alg,dfg in df.groupby('algorithm'):\n",
    "#     print(alg)\n",
    "    for s in seeds:\n",
    "        dfgs = dfg.loc[dfg.random_state==s]\n",
    "        for d in datasets:\n",
    "            if d not in dfgs['dataset'].unique():\n",
    "#                 ipdb.set_trace()\n",
    "                missing.append({'algorithm':alg, 'random_state':s,'dataset':d,'value':'missing'})\n",
    "#                 print(missing[-1])\n",
    "#     print(40*'-')\n",
    "    \n",
    "df_missing = pd.DataFrame.from_records(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b339b6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.groupby(['algorithm'])['r2_test_diff'].median().sort_values()\n",
    "alg_order = tmp.index\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5196a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['dataset','algorithm'])['r2_test'].median().unstack().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deabe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plt = df_sum.copy()\n",
    "alg_order = df_plt.groupby(['algorithm'])['r2_test_diff'].median().sort_values().index[::-1]\n",
    "g = sns.pointplot(\n",
    "#     showfliers=False,\n",
    "#     dodge=False,\n",
    "    join=False,\n",
    "    estimator=np.median,\n",
    "    data=df_plt,\n",
    "    y='algorithm',\n",
    "    order=alg_order,\n",
    "    hue_order=alg_order,\n",
    "    x='r2_test_diff',\n",
    "#     hue='dataset',\n",
    "    hue='algorithm',\n",
    "    palette='flare',\n",
    ")\n",
    "plt.plot([0, 0],g.get_ylim(),'--r')\n",
    "g.legend_.remove()\n",
    "g.set(\n",
    "#    xlim=(-1,1),\n",
    "#    xscale='log' \n",
    "     )\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('R2 Test Difference from Linear Regression (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efc7474",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plt = df_sum.copy()\n",
    "alg_order = df_sum.groupby(['algorithm'])['r2_test_rank_diff'].mean().sort_values().index\n",
    "g = sns.pointplot(\n",
    "#     showfliers=False,\n",
    "#     dodge=False,\n",
    "    join=False,\n",
    "#     estimator=np.median,\n",
    "    data=df_sum,\n",
    "    y='algorithm',\n",
    "    order=alg_order,\n",
    "    hue_order=alg_order,\n",
    "    x='r2_test_rank_diff',\n",
    "#     hue='dataset',\n",
    "    hue='algorithm',\n",
    "    palette='flare'\n",
    ")\n",
    "y0,y1 = g.get_ylim()\n",
    "x0,x1 = g.get_xlim()\n",
    "plt.plot([0, 0],g.get_ylim(),'-r', linewidth=1, alpha=0.7)\n",
    "# plt.fill_betweenx([0,g.get_xlim()[1], 0, g.get_xlim()[1]],.8*np.asarray(g.get_ylim()), alpha=0.2)\n",
    "plt.fill([0,x1,x1,0,0],[y0,y0,y1,y1,y0], alpha=0.2)\n",
    "g.legend_.remove()\n",
    "g.set(\n",
    "#    xlim=(-1,1),\n",
    "#    xscale='log' \n",
    "     )\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('$R^2$ test rank difference from LinearRegression (lower is better)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b3bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(['algorithm','dataset'])['r2_test'].median().unstack().loc[alg_order].round(3)\n",
    "df_plt = df.loc[df.algorithm!='LinearRegression']\n",
    "alg_order = df_plt.groupby(['algorithm'])['time_hr'].median().sort_values().index\n",
    "g = sns.stripplot(\n",
    "#     showfliers=False,\n",
    "#     dodge=False,\n",
    "#     join=False,\n",
    "#     estimator=np.median,\n",
    "    data=df_plt,\n",
    "    y='algorithm',\n",
    "    order=alg_order,\n",
    "    x='time_hr',\n",
    "    hue='dataset',\n",
    "    palette='colorblind'\n",
    ")\n",
    "plt.plot([0, 0],g.get_ylim(), '--r')\n",
    "g.legend_.remove()\n",
    "g.set(\n",
    "#    xlim=(-1,1),\n",
    "   xscale='log' \n",
    "     )\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Time (hr)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f792ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(['algorithm','dataset'])['r2_test'].median().unstack().loc[alg_order].round(3)\n",
    "df_plt = df.loc[df.algorithm=='eql']\n",
    "alg_order = df_plt.groupby(['algorithm'])['time_hr'].median().sort_values().index\n",
    "g = sns.stripplot(\n",
    "#     showfliers=False,\n",
    "#     dodge=False,\n",
    "#     join=False,\n",
    "#     estimator=np.median,\n",
    "    data=df_plt,\n",
    "    y='algorithm',\n",
    "    order=alg_order,\n",
    "    x='time_hr',\n",
    "    hue='dataset',\n",
    "    palette='colorblind'\n",
    ")\n",
    "plt.plot([0, 0],g.get_ylim(), '--r')\n",
    "# g.legend_.remove()\n",
    "plt.legend(loc=[1.1,0])\n",
    "g.set(\n",
    "#    xlim=(-1,1),\n",
    "#    xscale='log' \n",
    "     )\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Time (hr)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a59a0c",
   "metadata": {},
   "source": [
    "# catplot fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_catplot(derder, measure, gkwargs={}, **kwargs):\n",
    "    df_plt = derder.copy()\n",
    "    alg_order = df_plt.groupby(['algorithm'])[measure].median().sort_values().index\n",
    "    if 'r2' in measure: \n",
    "        alg_order = alg_order[::-1]\n",
    "   \n",
    "    PK = dict(\n",
    "        kind='point',\n",
    "        estimator=np.median,\n",
    "        join=False,\n",
    "        data=df_plt,\n",
    "        x=measure,\n",
    "        y='algorithm',\n",
    "        col='dataset',\n",
    "        col_wrap=5,\n",
    "        order=alg_order,\n",
    "        hue_order=alg_order,\n",
    "        palette='flare',\n",
    "        aspect=0.6,\n",
    "    )\n",
    "    PK.update(kwargs)\n",
    "    g = sns.catplot(**PK)\n",
    "    if 'r2' in measure and 'diff' not in measure:\n",
    "        g.set(xlim=[-.1,1.1])\n",
    "    g.set(**gkwargs)\n",
    "    \n",
    "    lr_loc = np.where(np.asarray(alg_order)=='LinearRegression')[0][0]\n",
    "    for ax in g.axes.flat:\n",
    "        ax.grid(axis='y')\n",
    "    for d,ax in g.axes_dict.items():\n",
    "        lr = df_plt.loc[(df_plt.algorithm=='LinearRegression') \n",
    "                    & (df_plt.dataset==d)][measure].median()\n",
    "        ax.plot([lr, lr],[0,len(alg_order)-1], '--k')\n",
    "        ax.plot([ax.get_xlim()[0],lr],[lr_loc,lr_loc], '--k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fa7bef",
   "metadata": {},
   "source": [
    "# r2 test difference from linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9fa730",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_catplot(df, 'r2_test_diff', sharex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36eb07b",
   "metadata": {},
   "source": [
    "# mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_catplot(df, 'mse_test',sharex=False, gkwargs=dict(xscale='log'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa48e413",
   "metadata": {},
   "source": [
    "# r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c221f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_catplot(df, 'r2_test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
